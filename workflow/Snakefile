from pathlib import Path

from snakemake.io import expand
from snakemake.utils import validate


## configuration ##

validate(config, "schemas/config.yml")

## variables ##

root = Path("results") / (config["pid"] or config["acc"])
logs = Path("logs") / (config["pid"] or config["acc"])

## rules ##

localrules:
  all,
  ffref,
  popmeta,
  extract,
  beautify

rule all:
  input:
    expand(
      root / "bactdate" / "{model}-{nbac}.qs",
      model=config["model"],
      nbac=range(1, config["nbac"] + 1)
    ),
    expand(
      root / "treeannotator" / "{clock}-{coal}-{nbeast}.tree",
      clock=config["clock"],
      coal=config["coal"],
      nbeast=range(1, config["nbeast"] + 1)
    )

rule ffref:
  message:
    """
    Retrieve {params.acc} {params.pid} from {input.fdb:q}, generating a FASTA/GenBank file.
    """
  group:
    "evopopgen"
  input:
    fdb = config["fdb"]
  output:
    fas = root / "ffref" / "ref.fasta",
    gbk = root / "ffref" / "ref.gb"
  log:
    log = logs / "ffref" / "ffref.log"
  params:
    acc = config["acc"],
    pid = config["pid"]
  threads:
    1
  conda:
    "envs/py.yml"
  script:
    "scripts/ffref.py"

rule blast:
  message:
    """
    Run BLAST+, optimizing for highly similar sequences, querying {params.bdb:q}.
    """
  group:
    "evopopgen"
  input:
    qry = rules.ffref.output.fas
  output:
    tsv = root / "blast" / "hits.tsv"
  log:
    log = logs / "blast" / "blast.log"
  params:
    bdb = config["bdb"]
  conda:
    "envs/blast.yml"
  threads:
    config["threads"]
  shell:
    """
    blastn \
      -task megablast \
      -db {params.bdb:q} \
      -query {input.qry:q} \
      -outfmt "7 std qlen sstrand staxid stitle" \
      -num_threads {threads} \
      -subject_besthit \
      -out {output.tsv:q}
    """

rule popmeta:
  message:
    """
    Generate the measurably evolving population metadata set, filter qpidcov >= {params.thr}.
    """
  group:
    "evopopgen"
  input:
    hit = rules.blast.output.tsv,
    tsv = config["tsv"]
  log:
    log = logs / "popmeta" / "popmeta.log"
  params:
    thr = config["thr"]
  output:
    tsv = root / "popmeta" / "meta.tsv",
    ssv = root / "popmeta" / "ebat.ssv",
    sed = root / "popmeta" / "date.sed"
  conda:
    "envs/R.yml"
  script:
    "scripts/popmeta.R"

rule extract:
  message:
    """
    Extract sequences from {params.bdb:q}.
    """
  group:
    "evopopgen"
  input:
    ssv = rules.popmeta.output.ssv,
    sed = rules.popmeta.output.sed
  output:
    fas = root / "extract" / "seq.fasta"
  log:
    log = logs / "extract" / "exract.log"
  params:
    bdb = config["bdb"]
  threads:
    1
  conda:
    "envs/blast.yml"
  shell:
    """
    blastdbcmd -db {params.bdb:q} -entry_batch {input.ssv:q} | \
      sed -e "s/:.*//" -E -f {input.sed:q} > {output.fas:q}
    """

rule mafft:
  message:
    """
    Perform multiple sequence alignment using MAFFT.
    """
  group:
    "evopopgen"
  input:
    fas = rules.extract.output.fas
  output:
    fas = root / "mafft" / "msa.fasta",
    log = root / "mafft" / "msa.log"
  log:
    log = logs / "mafft" / "mafft.log"
  params:
    bdb = config["bdb"]
  threads:
    config["threads"]
  conda:
    "envs/mafft.yml"
  shell:
    """
    mafft --auto --thread {threads} {input.fas:q} 2> {output.log:q} | \
      # convert ambiguous bases and non-gap characters to N
      sed "#^[^>]# s#[^ACGTNacgtn]#n#g" > {output.fas:q}
    """

rule gubbins:
  message:
    """
    Infer maximum-likelihood tree and recombination events using Gubbins.
    """
  group:
    "evopopgen"
  input:
    msa = rules.mafft.output.fas
  output:
    log = root / "gubbins" / "gub.log"
  log:
    log = logs / "gubbins" / "gubbins.log"
  params:
    pre = root / "gubbins" / "gub",
    itr = config["itr"],
    gap = config["gap"]
  threads:
    config["threads"]
  conda:
    "envs/gubbins.yml"
  shell:
    """
    run_gubbins.py {input.msa:q} \
      -i {params.itr} -f {params.gap} -p {params.pre:q} -c {threads} > {output.log:q}
    """

rule iqtree:
  message:
    """
    Infer maximum-likelihood tree and model of sequence evolution.
    """
  group:
    "evopopgen"
  input:
    msa = rules.mafft.output.fas
  output:
    log = root / "iqtree" / "iqt.log"
  log:
    log = logs / "iqtree" / "iqtree.log"
  params:
    pre = root / "iqtree" / "iqt"
  threads:
    config["threads"]
  conda:
    "envs/iqtree.yml"
  shell:
    """
    iqtree -redo -s {input.msa:q} -pre "{params.pre:q}" -m TESTONLY -nt {threads} > /dev/null 2> {log:q}
    """

rule bactdate:
  message:
    """
    Infer recombination-aware chronogram using BactDating: {params.mod} {params.rep}/{params.nrep}.
    """
  input:
    log = rules.gubbins.output.log
  output:
    qs = root / "bactdate" / "{model}-{nbac}.qs"
  log:
    log = logs / "bactdate" / "{model}-{nbac}.log"
  params:
    mod = lambda wildcards, output: Path(output[0]).stem.split("-")[0],
    rep = lambda wildcards, output: Path(output[0]).stem.split("-")[1],
    nrep = config["nbac"],
    nbi = config["nbIts"],
    thn = config["thin"]
  threads:
    1
  conda:
    "envs/R.yml"
  script:
    "scripts/bactdate.R"

rule beautify:
  message:
    """
    Generate BEAST XML input files: {params.clock}-{params.coal} {params.rep}/{params.nrep}.
    """
  input:
    fas = rules.mafft.output.fas,
    log = rules.iqtree.output.log
  output:
    xml = root / "beautify" / "{clock}-{coal}-{nbeast}.xml"
  log:
    log = logs / "beautify" / "{clock}-{coal}-{nbeast}.log"
  params:
    mcmc_len = config["mcmc_len"],
    mcmc_echo = config["mcmc_echo"],
    mle_len = config["mle_len"],
    mle_echo = config["mle_echo"],
    mle_step = config["mle_step"],
    stem = lambda wildcards, output: Path(output[0]).stem,
    clock = lambda wildcards, output: Path(output[0]).stem.split("-")[0],
    coal = lambda wildcards, output: Path(output[0]).stem.split("-")[1],
    rep = lambda wildcards, output: Path(output[0]).stem.split("-")[2],
    nrep = config["nbeast"]
  threads:
    1
  conda:
    "envs/py.yml"
  script:
    "scripts/beautify/beautify.py"

rule beast:
  message:
    """
    Infer chronogram using BEAST: {params.clock}-{params.coal} {params.rep}/{params.nrep}.
    """
  input:
    xml = root / "beautify" / "{clock}-{coal}-{nbeast}.xml"
  output:
    trees = root / "beast" / "{clock}-{coal}-{nbeast}.trees"
  log:
    log = root / "beast" / "{clock}-{coal}-{nbeast}.log"
  params:
    root = root / "beast",
    pwd = Path().absolute(),
    clock = lambda wildcards, output: Path(output[0]).stem.split("-")[0],
    coal = lambda wildcards, output: Path(output[0]).stem.split("-")[1],
    rep = lambda wildcards, output: Path(output[0]).stem.split("-")[2],
    nrep = config["nbeast"]
  threads:
     config["threads"]
  conda:
     "envs/beast.yml"
  shell:
    """
    mkdir -p {params.root:q}
    cd {params.root:q} || exit
    # use overwrite for now until a checkpoint method is devised...
    beast -overwrite -threads {threads} {params.pwd:q}/{input.xml:q} > {params.pwd:q}/{log:q}
    """

rule treeannotator:
  message:
    """
    Calculate the MCC tree w/
    {params.heights} heights & burn-in @ {params.burnin} & limit @ {params.limit}:
    {params.clock}-{params.coal} {params.rep}/{params.nrep}.
    """
  input:
    trees = root / "beast" / "{clock}-{coal}-{nbeast}.trees"
  output:
    mcc = root / "treeannotator" / "{clock}-{coal}-{nbeast}.tree"
  log:
    log = root / "treeannotator" / "{clock}-{coal}-{nbeast}.log"
  params:
    heights = config["heights"],
    burnin = max(1, int(round(config["burnin"] * config["mcmc_len"]))),
    limit = config["limit"],
    clock = lambda wildcards, output: Path(output[0]).stem.split("-")[0],
    coal = lambda wildcards, output: Path(output[0]).stem.split("-")[1],
    rep = lambda wildcards, output: Path(output[0]).stem.split("-")[2],
    nrep = config["nbeast"]
  conda:
     "envs/beast.yml"
  threads:
    1
  shell:
    """
    treeannotator \
        -heights {params.heights} -burnin {params.burnin} -limit {params.limit} \
        {input.trees:q} {output.mcc:q} > {log:q} 2>&1
    """
